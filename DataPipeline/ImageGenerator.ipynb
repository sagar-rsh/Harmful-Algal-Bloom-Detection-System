{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25fd8030-90d3-4b97-b3c8-e275824dd371",
   "metadata": {},
   "source": [
    "## pip install pandas numpy matplotlib scipy earthaccess netCDF4 h5py pyproj opencv-python pillow jupyter\n",
    "#### HABNet Image Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deacaaa2-d06c-4a0c-9ac9-12ce56266bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.spatial import ConvexHull\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56202ac4-369a-4f88-8cd1-e26fd87da670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts h5 datacubes to png images\n",
    "class HABNetImageGenerator:\n",
    "    def __init__(self, input_res=2000, output_res=1000, alpha_size=2):\n",
    "        self.input_res = input_res\n",
    "        self.output_res = output_res\n",
    "        self.alpha_size = alpha_size\n",
    "        self.fract = output_res / input_res  # e.g., 1000/2000 = 0.5\n",
    "        \n",
    "    # convert UTM coordinates to grid coordinates [0,50]    \n",
    "    def convert_utm_to_grid_coords(self, utm_x, utm_y, center_utm_x, center_utm_y):\n",
    "        \n",
    "        # spatial extent in m\n",
    "        extent_m = 100000  # 100km in meters\n",
    "        resolution_m = 2000  # 2km in meters\n",
    "        \n",
    "        # convert from UTM to relative coordinates\n",
    "        rel_x = utm_x - center_utm_x\n",
    "        rel_y = utm_y - center_utm_y\n",
    "        \n",
    "        # convert to grid coordinates [0, 50]\n",
    "        # center of grid is 25, extent is +/- 25\n",
    "        grid_x = (rel_x / resolution_m) + 25\n",
    "        grid_y = (rel_y / resolution_m) + 25\n",
    "        \n",
    "        return grid_x, grid_y\n",
    "\n",
    "    # output interpolation grid\n",
    "    def setup_output_grid(self, input_range_x, input_range_y):\n",
    "        \n",
    "        x_coords = np.arange(\n",
    "            input_range_x[0] + self.fract/2, \n",
    "            input_range_x[1], \n",
    "            self.fract\n",
    "        )\n",
    "        y_coords = np.arange(\n",
    "            input_range_y[0] + self.fract/2, \n",
    "            input_range_y[1], \n",
    "            self.fract\n",
    "        )\n",
    "        \n",
    "        xq, yq = np.meshgrid(x_coords, y_coords)\n",
    "        return xq, yq\n",
    "\n",
    "    # grid data to outpu\n",
    "    def get_image(self, output_xq, output_yq, input_xp, input_yp, input_up):\n",
    "    \n",
    "        if len(input_xp) < 4:  # need minimum points for interpolation\n",
    "            return np.full(output_xq.shape, np.nan)\n",
    "        \n",
    "        try:\n",
    "            # griddata interpolation\n",
    "            output_image = griddata(\n",
    "                np.column_stack([input_xp, input_yp]), \n",
    "                input_up,\n",
    "                np.column_stack([output_xq.ravel(), output_yq.ravel()]),\n",
    "                method='linear',\n",
    "                fill_value=np.nan\n",
    "            ).reshape(output_xq.shape)\n",
    "            \n",
    "            # fill remaining nans with nearest neighbor\n",
    "            if np.any(np.isnan(output_image)):\n",
    "                nn_image = griddata(\n",
    "                    np.column_stack([input_xp, input_yp]), \n",
    "                    input_up,\n",
    "                    np.column_stack([output_xq.ravel(), output_yq.ravel()]),\n",
    "                    method='nearest',\n",
    "                    fill_value=np.nan\n",
    "                ).reshape(output_xq.shape)\n",
    "                \n",
    "                nan_mask = np.isnan(output_image)\n",
    "                output_image[nan_mask] = nn_image[nan_mask]\n",
    "                \n",
    "            return output_image\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"gridding failed: {e}\")\n",
    "            return np.full(output_xq.shape, np.nan)\n",
    "\n",
    "    # safe normalization\n",
    "    def normalize(self, image, min_val, max_val):\n",
    "        \n",
    "        # check for all nans\n",
    "        if not np.any(np.isfinite(image)):\n",
    "            return np.zeros(image.shape, dtype=np.uint8)\n",
    "        \n",
    "        # use actual data range if range is invalid\n",
    "        actual_min = np.nanmin(image)\n",
    "        actual_max = np.nanmax(image)\n",
    "        \n",
    "        print(f\"    Data range: {actual_min:.6f} to {actual_max:.6f}\")\n",
    "        print(f\"    Norm range: {min_val:.6f} to {max_val:.6f}\")\n",
    "        \n",
    "        # if min is  max, use data range\n",
    "        if abs(max_val - min_val) < 1e-10:\n",
    "            print(f\"    Using actual range\")\n",
    "            min_val = actual_min\n",
    "            max_val = actual_max\n",
    "            \n",
    "            # if still equal, return middle gray\n",
    "            if abs(max_val - min_val) < 1e-10:\n",
    "                return np.full(image.shape, 128, dtype=np.uint8)\n",
    "        \n",
    "        # normalize\n",
    "        normalized = (image - min_val) / (max_val - min_val)\n",
    "        normalized = np.clip(normalized, 0, 1)  # 0-1 range\n",
    "        quantized = np.round(255.0 * normalized)\n",
    "        quantized = np.nan_to_num(quantized, nan=0)  # nans become 0 (black)\n",
    "        \n",
    "        unique_vals = len(np.unique(quantized[quantized > 0]))\n",
    "        print(f\"    Output: {unique_vals} unique non-zero values\")\n",
    "        \n",
    "        return quantized.astype(np.uint8)\n",
    "\n",
    "    # process single h5 datacube to png images\n",
    "    def process_datacube_to_images(self, h5_file_path, output_base_dir, group_min_max=None):\n",
    "       \n",
    "        h5_file_path = Path(h5_file_path)\n",
    "        output_base_dir = Path(output_base_dir)\n",
    "        \n",
    "        print(f\"Processing datacube: {h5_file_path.name}\")\n",
    "        \n",
    "        with h5py.File(h5_file_path, 'r') as h5f:\n",
    "            # get modalitys\n",
    "            if 'Modnames' in h5f:\n",
    "                mod_names = [name.decode('utf-8') if isinstance(name, bytes) else name \n",
    "                           for name in h5f['Modnames'][:]]\n",
    "            else:\n",
    "                mod_names = [name for name in h5f.keys() if name != 'GroundTruth']\n",
    "            \n",
    "            print(f\"Found {len(mod_names)} modalities: {mod_names}\")\n",
    "            \n",
    "            # get center coordinates from ground truth\n",
    "            gt_group = h5f['GroundTruth']\n",
    "            center_lat = gt_group.attrs['thisLat']\n",
    "            center_lon = gt_group.attrs['thisLon']\n",
    "            print(f\"Event center: ({center_lat:.4f}, {center_lon:.4f})\")\n",
    "            \n",
    "            # setup output grid \n",
    "            input_range_x = [0, 50]\n",
    "            input_range_y = [0, 50]\n",
    "            output_xq, output_yq = self.setup_output_grid(input_range_x, input_range_y)\n",
    "            print(f\"Output image size: {output_xq.shape}\")\n",
    "            \n",
    "            # get number of days from first modality\n",
    "            first_mod = mod_names[0]\n",
    "            datacube_shape = h5f[first_mod]['Ims'].shape\n",
    "            number_of_days = datacube_shape[2] if len(datacube_shape) == 3 else 1\n",
    "            print(f\"Processing {number_of_days} days\")\n",
    "            \n",
    "            # compute min/max value\n",
    "            if group_min_max is None:\n",
    "                print(\"Computing min/max values from data...\")\n",
    "                group_min_max = self.get_min_max_from_datacube(h5f, mod_names)\n",
    "            \n",
    "            # estimate center UTM from first modality\n",
    "            center_utm_x = center_utm_y = None\n",
    "            for mod_name in mod_names:\n",
    "                if mod_name in h5f and 'PointsProj' in h5f[mod_name]:\n",
    "                    points_proj = h5f[mod_name]['PointsProj'][:]\n",
    "                    if len(points_proj) > 0:\n",
    "                        center_utm_x = np.mean(points_proj[:, 0])\n",
    "                        center_utm_y = np.mean(points_proj[:, 1])\n",
    "                        print(f\"Estimated center UTM: ({center_utm_x:.1f}, {center_utm_y:.1f})\")\n",
    "                        break\n",
    "            \n",
    "            if center_utm_x is None:\n",
    "                print(\"ERROR: Could not determine center UTM coordinates!\")\n",
    "                return\n",
    "            \n",
    "            # process each modality\n",
    "            for mod_idx, mod_name in enumerate(mod_names):\n",
    "                print(f\"\\n  Modality {mod_idx+1}/{len(mod_names)}: {mod_name}\")\n",
    "                \n",
    "                # create output directory for this modality\n",
    "                mod_output_dir = output_base_dir / str(mod_idx + 1)\n",
    "                mod_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                if mod_name not in h5f:\n",
    "                    print(f\"    Not found in file\")\n",
    "                    # create empty images\n",
    "                    for day in range(1, number_of_days + 1):\n",
    "                        empty_image = np.zeros(output_xq.shape, dtype=np.uint8)\n",
    "                        Image.fromarray(empty_image).save(mod_output_dir / f\"{day:02d}.png\")\n",
    "                    continue\n",
    "                \n",
    "                mod_group = h5f[mod_name]\n",
    "                \n",
    "                # get min/max for this modality\n",
    "                if mod_idx < len(group_min_max):\n",
    "                    this_min, this_max = group_min_max[mod_idx]\n",
    "                else:\n",
    "                    # fallback\n",
    "                    if 'PointsProj' in mod_group:\n",
    "                        points_proj = mod_group['PointsProj'][:]\n",
    "                        if len(points_proj) > 0:\n",
    "                            this_min = np.nanmin(points_proj[:, 2])\n",
    "                            this_max = np.nanmax(points_proj[:, 2])\n",
    "                        else:\n",
    "                            this_min, this_max = 0, 1\n",
    "                    else:\n",
    "                        this_min, this_max = 0, 1\n",
    "                \n",
    "                print(f\"    Min/Max: {this_min:.6f} / {this_max:.6f}\")\n",
    "                \n",
    "                # get projected points data\n",
    "                if 'PointsProj' in mod_group:\n",
    "                    points_proj = mod_group['PointsProj'][:]\n",
    "                    \n",
    "                    # process each day\n",
    "                    for day in range(1, number_of_days + 1):\n",
    "                        try:\n",
    "                            # filter points for this day: day 1 -> time 0\n",
    "                            time_indices = (points_proj[:, 3] >= day-1) & (points_proj[:, 3] < day)\n",
    "                            \n",
    "                            if not np.any(time_indices):\n",
    "                                print(f\"      Day {day}: NO DATA\")\n",
    "                                output_image = np.zeros(output_xq.shape)\n",
    "                            else:\n",
    "                                day_points = points_proj[time_indices]\n",
    "                                utm_x = day_points[:, 0]\n",
    "                                utm_y = day_points[:, 1]\n",
    "                                values = day_points[:, 2]\n",
    "                                \n",
    "                                # convert UTM to grid coordinates\n",
    "                                grid_x, grid_y = self.convert_utm_to_grid_coords(\n",
    "                                    utm_x, utm_y, center_utm_x, center_utm_y\n",
    "                                )\n",
    "                                \n",
    "                                print(f\"      Day {day}: {len(day_points)} points\")\n",
    "                                print(f\"        UTM: X({np.min(utm_x):.1f}-{np.max(utm_x):.1f}) Y({np.min(utm_y):.1f}-{np.max(utm_y):.1f})\")\n",
    "                                print(f\"        Grid: X({np.min(grid_x):.1f}-{np.max(grid_x):.1f}) Y({np.min(grid_y):.1f}-{np.max(grid_y):.1f})\")\n",
    "                                \n",
    "                                # grid the data with converted coords\n",
    "                                output_image = self.get_image(\n",
    "                                    output_xq, output_yq, grid_x, grid_y, values\n",
    "                                )\n",
    "                            \n",
    "                            # normalize\n",
    "                            quantized_image = self.normalize(\n",
    "                                output_image, this_min, this_max\n",
    "                            )\n",
    "                            \n",
    "                            # save as png\n",
    "                            output_file = mod_output_dir / f\"{day:02d}.png\"\n",
    "                            Image.fromarray(quantized_image).save(output_file)\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"        Error processing day {day}: {e}\")\n",
    "                            empty_image = np.zeros(output_xq.shape, dtype=np.uint8)\n",
    "                            Image.fromarray(empty_image).save(mod_output_dir / f\"{day:02d}.png\")\n",
    "                \n",
    "                else:\n",
    "                    print(f\"    No PointsProj data found\")\n",
    "                    # create empty images\n",
    "                    for day in range(1, number_of_days + 1):\n",
    "                        empty_image = np.zeros(output_xq.shape, dtype=np.uint8)\n",
    "                        Image.fromarray(empty_image).save(mod_output_dir / f\"{day:02d}.png\")\n",
    "                \n",
    "                print(f\"    Saved {number_of_days} images to {mod_output_dir}\")\n",
    "        \n",
    "        print(f\"✓ Completed: {h5_file_path.name}\")\n",
    "\n",
    "    # get min/max values from datacube\n",
    "    def get_min_max_from_datacube(self, h5f, mod_names):\n",
    "        group_min_max = []\n",
    "        \n",
    "        for mod_name in mod_names:\n",
    "            if mod_name in h5f and 'PointsProj' in h5f[mod_name]:\n",
    "                points_proj = h5f[mod_name]['PointsProj'][:]\n",
    "                if len(points_proj) > 0:\n",
    "                    values = points_proj[:, 2]  # value column\n",
    "                    min_val = np.nanmin(values)\n",
    "                    max_val = np.nanmax(values)\n",
    "                else:\n",
    "                    min_val, max_val = 0, 1\n",
    "            else:\n",
    "                min_val, max_val = 0, 1\n",
    "            \n",
    "            group_min_max.append((min_val, max_val))\n",
    "        \n",
    "        return group_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c831bbf-7f62-4be7-a9de-a0ff0126589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_all_datacubes_to_images(datacube_dir, output_dir, use_global_minmax=False):\n",
    "    datacube_dir = Path(datacube_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    # find all h5 files\n",
    "    h5_files = list(datacube_dir.glob(\"*.h5\"))\n",
    "    if not h5_files:\n",
    "        print(f\"No H5 files found in {datacube_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(h5_files)} H5 datacube files\")\n",
    "    \n",
    "    # compute global min/max\n",
    "    global_min_max = None\n",
    "    if use_global_minmax:\n",
    "        pass\n",
    "    \n",
    "    # create image generator\n",
    "    generator = HABNetImageGenerator(input_res=2000, output_res=1000, alpha_size=2)\n",
    "    \n",
    "    # process each datacube\n",
    "    for idx, h5_file in enumerate(h5_files):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing datacube {idx+1}/{len(h5_files)}\")\n",
    "        \n",
    "        # create output directory for this datacube\n",
    "        datacube_output_dir = output_dir / h5_file.stem\n",
    "        datacube_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            generator.process_datacube_to_images(\n",
    "                h5_file, \n",
    "                datacube_output_dir, \n",
    "                group_min_max=global_min_max\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed to process {h5_file.name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Image conversion complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc12fc-e57d-44c8-af35-abf131f581c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # test the fix\n",
    "    datacube_directory = \"habnet_datacube_data/processed_h5_datacubes\"\n",
    "    output_directory = \"habnet_datacube_data/png_images\"\n",
    "    \n",
    "    convert_all_datacubes_to_images(\n",
    "        datacube_dir=datacube_directory,\n",
    "        output_dir=output_directory,\n",
    "        use_global_minmax=False \n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
