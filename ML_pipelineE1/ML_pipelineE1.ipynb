{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53vFIG0s7jMk"
      },
      "outputs": [],
      "source": [
        "# HABNet ML Pipeline (Regenerated: Full Version)\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from xgboost import XGBClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, TimeDistributed, LSTM, Masking, Input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Constants\n",
        "N_DAYS = 10\n",
        "N_MODALITIES = 7\n",
        "IMG_SIZE = (100, 100)\n",
        "DATASET_DIR = 'data_set'  # Must have folders '0/' and '1/' with subfolders as samples\n",
        "\n",
        "# -----------------------------\n",
        "# Load Data\n",
        "# -----------------------------\n",
        "def load_real_data(base_dir):\n",
        "    X, y = [], []\n",
        "\n",
        "    for label_dir in ['0', '1']:\n",
        "        label = int(label_dir)\n",
        "        label_path = os.path.join(base_dir, label_dir)\n",
        "        if not os.path.exists(label_path):\n",
        "            continue\n",
        "\n",
        "        for sample_folder in os.listdir(label_path):\n",
        "            sample_path = os.path.join(label_path, sample_folder)\n",
        "            day_images = []\n",
        "            for day in range(1, N_DAYS + 1):\n",
        "                modalities = []\n",
        "                for mod in range(1, N_MODALITIES + 1):\n",
        "                    img_path = os.path.join(sample_path, f'{mod}', f'{day:02}.png')\n",
        "                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "                    if img is not None:\n",
        "                        img = cv2.resize(img, IMG_SIZE)\n",
        "                        img = img.astype('float32') / 255.0\n",
        "                        modalities.append(img)\n",
        "                if modalities:\n",
        "                    day_stack = np.stack(modalities, axis=-1)\n",
        "                    day_images.append(day_stack)\n",
        "            if day_images:\n",
        "                sequence = np.stack(day_images, axis=0)  # (10, H, W, 7)\n",
        "                X.append(sequence)\n",
        "                y.append(label)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = load_real_data(DATASET_DIR)\n",
        "print(\"Loaded:\", X.shape, y.shape)\n",
        "\n",
        "# -----------------------------\n",
        "# Classical Models\n",
        "# -----------------------------\n",
        "X_flat = X.reshape(len(X), -1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_flat, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"\\nLogistic Regression\")\n",
        "logreg = LogisticRegression(max_iter=200)\n",
        "logreg.fit(X_train, y_train)\n",
        "print(classification_report(y_test, logreg.predict(X_test)))\n",
        "\n",
        "print(\"\\nRidge Classifier\")\n",
        "ridge = RidgeClassifier()\n",
        "ridge.fit(X_train, y_train)\n",
        "print(classification_report(y_test, ridge.predict(X_test)))\n",
        "\n",
        "print(\"\\nXGBoost\")\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "xgb.fit(X_train, y_train)\n",
        "print(classification_report(y_test, xgb.predict(X_test)))\n",
        "\n",
        "# -----------------------------\n",
        "# Deep Learning Model\n",
        "# -----------------------------\n",
        "X_train_dl, X_test_dl, y_train_dl, y_test_dl = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(N_DAYS, IMG_SIZE[0], IMG_SIZE[1], N_MODALITIES)),\n",
        "    TimeDistributed(Conv2D(16, (3, 3), activation='relu')),\n",
        "    TimeDistributed(MaxPooling2D((2, 2))),\n",
        "    TimeDistributed(Conv2D(32, (3, 3), activation='relu')),\n",
        "    TimeDistributed(MaxPooling2D((2, 2))),\n",
        "    TimeDistributed(Flatten()),\n",
        "    Masking(mask_value=0.0),\n",
        "    LSTM(64),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_dl, y_train_dl, epochs=10, batch_size=4, validation_split=0.1)\n",
        "\n",
        "# Evaluation\n",
        "preds = (model.predict(X_test_dl) > 0.5).astype(int)\n",
        "print(\"\\nDeep Learning Model Report:\")\n",
        "print(classification_report(y_test_dl, preds))\n"
      ]
    }
  ]
}